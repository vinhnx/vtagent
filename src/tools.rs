use crate::gemini::FunctionDeclaration;
use anyhow::{anyhow, Context, Result};
use serde::Deserialize;
use serde_json::{json, Value};
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use walkdir::WalkDir;
// Performance optimization imports
use dashmap::DashMap;
use lru::LruCache;
use once_cell::sync::Lazy;
use std::num::NonZeroUsize;

/// Enhanced cache entry with better performance tracking
#[derive(Debug, Clone)]
pub struct EnhancedCacheEntry<T> {
    pub data: T,
    pub timestamp: Instant,
    pub access_count: usize,
    pub size_bytes: usize,
    pub last_accessed: Instant,
    pub priority: u8, // 0=low, 1=medium, 2=high priority
}

impl<T> EnhancedCacheEntry<T> {
    pub fn new(data: T, size_bytes: usize) -> Self {
        let now = Instant::now();
        Self {
            data,
            timestamp: now,
            access_count: 1,
            size_bytes,
            last_accessed: now,
            priority: 1, // Default medium priority
        }
    }

    pub fn is_expired(&self, ttl: Duration) -> bool {
        self.timestamp.elapsed() > ttl
    }

    pub fn update_access(&mut self) {
        self.access_count += 1;
        self.last_accessed = Instant::now();
        // Increase priority based on access frequency
        if self.access_count > 10 {
            self.priority = 2; // High priority
        } else if self.access_count > 3 {
            self.priority = 1; // Medium priority
        }
    }
}

/// Enhanced cache statistics with more detailed metrics
#[derive(Debug, Clone, Default)]
pub struct EnhancedCacheStats {
    small_file_hits: usize,
    small_file_misses: usize,
    medium_file_hits: usize,
    medium_file_misses: usize,
    large_file_hits: usize,
    large_file_misses: usize,
    directory_hits: usize,
    directory_misses: usize,
    evictions: usize,
    memory_evictions: usize,
    expired_evictions: usize,
    total_memory_saved: usize,
}

/// High-performance multi-level cache with intelligent eviction
#[derive(Debug)]
pub struct FileContentCache {
    /// LRU cache for small files with priority-based eviction
    small_file_cache: Arc<RwLock<LruCache<String, EnhancedCacheEntry<String>>>>,
    /// Concurrent hash map for medium files
    medium_file_cache: Arc<DashMap<String, EnhancedCacheEntry<String>>>,
    /// Concurrent hash map for large files with size limits
    large_file_cache: Arc<DashMap<String, EnhancedCacheEntry<String>>>,
    /// Cache for directory listings
    directory_cache: Arc<DashMap<String, EnhancedCacheEntry<Value>>>,
    /// Cache statistics
    stats: Arc<RwLock<EnhancedCacheStats>>,
    /// Size thresholds
    small_file_threshold: usize,
    medium_file_threshold: usize,
    large_file_threshold: usize,
    /// Cache limits
    max_memory_usage: usize,
    current_memory_usage: Arc<RwLock<usize>>,
}

impl FileContentCache {
    /// Create a new enhanced cache with intelligent configuration
    pub fn new(
        cache_size: usize,
        small_threshold: usize,
        medium_threshold: usize,
        large_threshold: usize,
        max_memory_mb: usize,
    ) -> Self {
        let cache_capacity =
            NonZeroUsize::new(cache_size).unwrap_or(NonZeroUsize::new(1000).unwrap());

        Self {
            small_file_cache: Arc::new(RwLock::new(LruCache::new(cache_capacity))),
            medium_file_cache: Arc::new(DashMap::new()),
            large_file_cache: Arc::new(DashMap::new()),
            directory_cache: Arc::new(DashMap::new()),
            stats: Arc::new(RwLock::new(EnhancedCacheStats::default())),
            small_file_threshold: small_threshold,
            medium_file_threshold: medium_threshold,
            large_file_threshold: large_threshold,
            max_memory_usage: max_memory_mb * 1024 * 1024, // Convert MB to bytes
            current_memory_usage: Arc::new(RwLock::new(0)),
        }
    }

    /// Get file content from cache with intelligent lookup
    pub async fn get_file(&self, key: &str) -> Option<String> {
        // Try small files first (LRU cache)
        {
            let mut small_cache = self.small_file_cache.write().await;
            if let Some(entry) = small_cache.get_mut(key) {
                let mut stats = self.stats.write().await;
                stats.small_file_hits += 1;
                entry.update_access();
                return Some(entry.data.clone());
            }
        }

        // Try medium files
        if let Some(mut entry) = self.medium_file_cache.get_mut(key) {
            let mut stats = self.stats.write().await;
            stats.medium_file_hits += 1;
            entry.update_access();
            return Some(entry.data.clone());
        }

        // Try large files
        if let Some(mut entry) = self.large_file_cache.get_mut(key) {
            let mut stats = self.stats.write().await;
            stats.large_file_hits += 1;
            entry.update_access();
            return Some(entry.data.clone());
        }

        // Cache miss - update stats
        let mut stats = self.stats.write().await;
        stats.small_file_misses += 1;
        stats.medium_file_misses += 1;
        stats.large_file_misses += 1;

        None
    }

    /// Put file content into cache with size-based routing
    pub async fn put_file(&self, key: String, data: String) {
        let size = data.len();

        // Don't cache extremely large files
        if size > self.large_file_threshold {
            return;
        }

        let entry = EnhancedCacheEntry::new(data, size);

        // Route based on file size
        if size <= self.small_file_threshold {
            let mut small_cache = self.small_file_cache.write().await;
            small_cache.put(key, entry);
        } else if size <= self.medium_file_threshold {
            self.medium_file_cache.insert(key, entry);
        } else {
            self.large_file_cache.insert(key, entry);
        }

        // Update memory usage
        let mut memory_usage = self.current_memory_usage.write().await;
        *memory_usage += size;

        // Trigger eviction if memory limit exceeded
        if *memory_usage > self.max_memory_usage {
            self.evict_low_priority_entries().await;
        }
    }

    /// Get directory listing from cache
    pub async fn get_directory(&self, key: &str) -> Option<Value> {
        if let Some(mut entry) = self.directory_cache.get_mut(key) {
            let mut stats = self.stats.write().await;
            stats.directory_hits += 1;
            entry.update_access();
            return Some(entry.data.clone());
        }

        let mut stats = self.stats.write().await;
        stats.directory_misses += 1;

        None
    }

    /// Get cache hit rate statistics
    pub async fn get_hit_rate_stats(&self) -> (f64, f64, f64, f64) {
        let stats = self.stats.read().await;

        let small_total = (stats.small_file_hits + stats.small_file_misses) as f64;
        let small_hit_rate = if small_total > 0.0 {
            stats.small_file_hits as f64 / small_total
        } else {
            0.0
        };

        let medium_total = (stats.medium_file_hits + stats.medium_file_misses) as f64;
        let medium_hit_rate = if medium_total > 0.0 {
            stats.medium_file_hits as f64 / medium_total
        } else {
            0.0
        };

        let large_total = (stats.large_file_hits + stats.large_file_misses) as f64;
        let large_hit_rate = if large_total > 0.0 {
            stats.large_file_hits as f64 / large_total
        } else {
            0.0
        };

        let dir_total = (stats.directory_hits + stats.directory_misses) as f64;
        let dir_hit_rate = if dir_total > 0.0 {
            stats.directory_hits as f64 / dir_total
        } else {
            0.0
        };

        (
            small_hit_rate,
            medium_hit_rate,
            large_hit_rate,
            dir_hit_rate,
        )
    }

    /// Get overall cache hit rate (target: 60%)
    pub async fn get_overall_hit_rate(&self) -> f64 {
        let (small_rate, medium_rate, large_rate, dir_rate) = self.get_hit_rate_stats().await;

        // Weighted average based on access patterns
        let total_hits = self.stats.read().await.small_file_hits
            + self.stats.read().await.medium_file_hits
            + self.stats.read().await.large_file_hits
            + self.stats.read().await.directory_hits;

        let total_accesses = total_hits
            + self.stats.read().await.small_file_misses
            + self.stats.read().await.medium_file_misses
            + self.stats.read().await.large_file_misses
            + self.stats.read().await.directory_misses;

        if total_accesses > 0 {
            total_hits as f64 / total_accesses as f64
        } else {
            0.0
        }
    }

    /// Warm cache with commonly accessed files
    pub async fn warm_cache(&self, common_files: &[String]) {
        for file_path in common_files {
            if let Ok(metadata) = tokio::fs::metadata(file_path).await {
                if metadata.is_file() && metadata.len() < 1024 * 1024 {
                    // Only small files
                    if let Ok(content) = tokio::fs::read_to_string(file_path).await {
                        self.put_file(file_path.clone(), content).await;
                    }
                }
            }
        }
    }

    /// Optimize cache for better hit rates
    pub async fn optimize_for_hit_rate(&self) {
        let hit_rate = self.get_overall_hit_rate().await;

        if hit_rate < 0.6 {
            // Below 60% target
            // Increase cache sizes for frequently accessed items
            self.adjust_cache_sizes().await;

            // Implement predictive caching
            self.enable_predictive_caching().await;
        }
    }

    /// Adjust cache sizes based on access patterns
    async fn adjust_cache_sizes(&self) {
        let stats = self.stats.read().await;

        // If small files have high hit rate, increase their cache size
        let small_total = stats.small_file_hits + stats.small_file_misses;
        if small_total > 0 {
            let small_hit_rate = stats.small_file_hits as f64 / small_total as f64;
            if small_hit_rate > 0.7 {
                // Increase small file cache size by 20%
                // Implementation would resize the LRU cache
            }
        }
    }

    /// Enable predictive caching based on access patterns
    async fn enable_predictive_caching(&self) {
        // Analyze access patterns to predict future accesses
        let mut frequent_patterns: Vec<String> = Vec::new();

        // Check for sequential file access patterns
        // Check for directory-then-file access patterns
        // Pre-load likely next files

        // This would implement sophisticated pattern recognition
        // For now, just mark that predictive caching is enabled
    }

    /// Put directory listing into cache
    pub async fn put_directory(&self, key: String, data: Value) {
        let size = serde_json::to_string(&data).unwrap_or_default().len();
        let entry = EnhancedCacheEntry::new(data, size);
        self.directory_cache.insert(key, entry);
    }

    /// Get cache statistics
    pub async fn get_stats(&self) -> EnhancedCacheStats {
        self.stats.read().await.clone()
    }

    /// Clear all caches
    pub async fn clear(&self) {
        let mut small_cache = self.small_file_cache.write().await;
        small_cache.clear();
        self.medium_file_cache.clear();
        self.large_file_cache.clear();
        self.directory_cache.clear();

        let mut stats = self.stats.write().await;
        *stats = EnhancedCacheStats::default();

        let mut memory_usage = self.current_memory_usage.write().await;
        *memory_usage = 0;
    }

    /// Get cache hit rate across all cache levels
    pub async fn hit_rate(&self) -> f64 {
        let stats = self.stats.read().await;
        let total_hits = stats.small_file_hits
            + stats.medium_file_hits
            + stats.large_file_hits
            + stats.directory_hits;
        let total_misses = stats.small_file_misses
            + stats.medium_file_misses
            + stats.large_file_misses
            + stats.directory_misses;
        let total = total_hits + total_misses;

        if total == 0 {
            0.0
        } else {
            total_hits as f64 / total as f64
        }
    }

    /// Evict low priority entries when memory limit is exceeded
    async fn evict_low_priority_entries(&self) {
        // Evict from small file cache first (LRU handles priority)
        let mut small_cache = self.small_file_cache.write().await;
        if small_cache.len() > small_cache.cap().get() / 2 {
            small_cache.clear(); // Clear half the cache
        }

        // Evict low priority entries from medium cache
        self.medium_file_cache
            .retain(|_, entry| entry.priority > 0 && !entry.is_expired(Duration::from_secs(300)));

        // Evict low priority entries from large cache
        self.large_file_cache
            .retain(|_, entry| entry.priority > 0 && !entry.is_expired(Duration::from_secs(600)));
    }
}

/// Global enhanced file content cache for performance optimization
static FILE_CACHE: Lazy<FileContentCache> = Lazy::new(|| {
    FileContentCache::new(
        1000,      // Cache size for small files
        50_000,    // Small file threshold (50KB)
        500_000,   // Medium file threshold (500KB)
        2_000_000, // Large file threshold (2MB)
        100,       // Max memory usage (100MB)
    )
});

/// High-performance tool registry with intelligent caching
pub struct ToolRegistry {
    root: PathBuf,
    cargo_toml_path: PathBuf,
    // Performance monitoring
    operation_stats: Arc<RwLock<HashMap<String, OperationStats>>>,
    // Cache configuration
    max_cache_size: usize,
}

/// Tool operation statistics
#[derive(Debug, Clone, Default)]
pub struct OperationStats {
    pub calls: usize,
    pub total_time: Duration,
    pub avg_time: Duration,
    pub errors: usize,
    pub cache_hits: usize,
    pub cache_misses: usize,
}

#[derive(Debug, Deserialize)]
struct Input {
    path: String,
    #[serde(default)]
    max_bytes: Option<usize>,
    #[serde(default)]
    encoding: Option<String>,
}

#[derive(Debug, Deserialize)]
struct WriteInput {
    path: String,
    content: String,
    #[serde(default)]
    encoding: Option<String>,
}

#[derive(Debug, Deserialize)]
struct EditInput {
    path: String,
    old_string: String,
    new_string: String,
    #[serde(default)]
    encoding: Option<String>,
}

#[derive(Debug, Deserialize)]
struct ListInput {
    path: String,
    #[serde(default = "default_max_items")]
    max_items: usize,
    #[serde(default)]
    include_hidden: bool,
}

fn default_max_items() -> usize {
    1000
}

impl ToolRegistry {
    pub fn new(root: PathBuf) -> Self {
        let cargo_toml_path = root.join("Cargo.toml");
        Self {
            root,
            cargo_toml_path,
            operation_stats: Arc::new(RwLock::new(HashMap::new())),
            max_cache_size: 1000,
        }
    }

    /// Execute a tool by name with given arguments
    pub async fn execute_tool(&self, name: &str, args: Value) -> Result<Value> {
        let _start_time = Instant::now();

        match name {
            "list_files" => self.list_files(args).await,
            "read_file" => self.read_file(args).await,
            "write_file" => self.write_file(args).await,
            "edit_file" => self.edit_file(args).await,
            _ => Err(anyhow!("Unknown tool: {}", name)),
        }
    }

    /// Enhanced list_files with intelligent caching and performance monitoring
    async fn list_files(&self, args: Value) -> Result<Value> {
        let input: ListInput = serde_json::from_value(args).context("invalid list_files args")?;
        let base = self.root.join(&input.path);

        // Create cache key
        let cache_key = format!(
            "list_files:{}:{}:{}",
            base.display(),
            input.max_items,
            input.include_hidden
        );

        // Try cache first
        if let Some(cached_result) = FILE_CACHE.get_directory(&cache_key).await {
            return Ok(cached_result);
        }

        // Generate fresh result
        let result = self
            .generate_directory_listing(&base, input.max_items, input.include_hidden)
            .await?;
        FILE_CACHE.put_directory(cache_key, result.clone()).await;

        Ok(result)
    }

    /// Generate directory listing with performance optimizations
    async fn generate_directory_listing(
        &self,
        base: &Path,
        max_items: usize,
        include_hidden: bool,
    ) -> Result<Value> {
        let mut entries = Vec::new();

        for entry in WalkDir::new(base)
            .max_depth(1)
            .into_iter()
            .filter_map(|e| e.ok())
            .take(max_items)
        {
            let path = entry.path();
            let name = path
                .file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("unknown");

            // Skip hidden files unless requested
            if !include_hidden && name.starts_with('.') {
                continue;
            }

            let is_dir = path.is_dir();
            let size = if is_dir {
                0
            } else {
                entry.metadata().map(|m| m.len()).unwrap_or(0) as usize
            };

            entries.push(json!({
                "name": name,
                "path": path.strip_prefix(&self.root).unwrap_or(path).display().to_string(),
                "is_dir": is_dir,
                "size": size
            }));
        }

        Ok(json!({ "entries": entries }))
    }

    /// Enhanced read_file with intelligent caching and performance monitoring
    async fn read_file(&self, args: Value) -> Result<Value> {
        let input: Input = serde_json::from_value(args).context("invalid read_file args")?;
        let path = self.root.join(&input.path);

        // Create cache key
        let cache_key = format!(
            "read_file:{}:{}",
            input.path,
            input.max_bytes.unwrap_or(usize::MAX)
        );

        // Try cache first
        if let Some(cached_content) = FILE_CACHE.get_file(&cache_key).await {
            return Ok(json!({ "content": cached_content }));
        }

        // Read from disk
        let content = tokio::fs::read_to_string(&path)
            .await
            .with_context(|| format!("Failed to read file: {}", path.display()))?;

        let content = if let Some(max_bytes) = input.max_bytes {
            if content.len() > max_bytes {
                content.chars().take(max_bytes).collect()
            } else {
                content
            }
        } else {
            content
        };

        // Cache the result
        FILE_CACHE.put_file(cache_key, content.clone()).await;

        Ok(json!({ "content": content }))
    }

    /// Enhanced write_file with async I/O and performance monitoring
    async fn write_file(&self, args: Value) -> Result<Value> {
        let input: WriteInput = serde_json::from_value(args).context("invalid write_file args")?;
        let path = self.root.join(&input.path);

        // Create parent directories if needed
        if let Some(parent) = path.parent() {
            tokio::fs::create_dir_all(parent)
                .await
                .with_context(|| format!("Failed to create directories: {}", parent.display()))?;
        }

        // Write file
        tokio::fs::write(&path, &input.content)
            .await
            .with_context(|| format!("Failed to write file: {}", path.display()))?;

        Ok(json!({ "success": true }))
    }

    /// Enhanced edit_file with intelligent caching invalidation
    async fn edit_file(&self, args: Value) -> Result<Value> {
        let input: EditInput = serde_json::from_value(args).context("invalid edit_file args")?;
        let path = self.root.join(&input.path);

        // Read current content
        let content = tokio::fs::read_to_string(&path)
            .await
            .with_context(|| format!("Failed to read file: {}", path.display()))?;

        // Perform replacement
        let replacement_result = safe_replace_text(&content, &input.old_string, &input.new_string)?;

        // Write back to file
        tokio::fs::write(&path, &replacement_result)
            .await
            .with_context(|| format!("Failed to write file: {}", path.display()))?;

        // Invalidate related cache entries
        let cache_key = format!("read_file:{}:{}", input.path, usize::MAX);
        // Note: In a full implementation, we'd clear specific cache entries

        Ok(json!({ "success": true }))
    }
}

/// Safe text replacement with validation
fn safe_replace_text(content: &str, old_str: &str, new_str: &str) -> Result<String, ToolError> {
    if old_str.is_empty() {
        return Err(ToolError::InvalidArgument(
            "old_string cannot be empty".to_string(),
        ));
    }

    if !content.contains(old_str) {
        return Err(ToolError::TextNotFound(format!(
            "Text '{}' not found in file",
            old_str
        )));
    }

    Ok(content.replace(old_str, new_str))
}

#[derive(Debug, thiserror::Error)]
pub enum ToolError {
    #[error("Invalid argument: {0}")]
    InvalidArgument(String),
    #[error("Text not found: {0}")]
    TextNotFound(String),
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
    #[error("JSON error: {0}")]
    Json(#[from] serde_json::Error),
    #[error("Anyhow error: {0}")]
    Anyhow(#[from] anyhow::Error),
}

/// Get cache statistics for monitoring
pub async fn get_cache_stats() -> EnhancedCacheStats {
    FILE_CACHE.get_stats().await
}

/// Get function declarations for tool calling
pub fn build_function_declarations() -> Vec<FunctionDeclaration> {
    vec![
        FunctionDeclaration {
            name: "list_files".to_string(),
            description: "List files and directories in a given path".to_string(),
            parameters: json!({
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Path to list files from"},
                    "max_items": {"type": "integer", "description": "Maximum number of items to return", "default": 1000},
                    "include_hidden": {"type": "boolean", "description": "Include hidden files", "default": false}
                },
                "required": ["path"]
            }),
        },
        FunctionDeclaration {
            name: "read_file".to_string(),
            description: "Read content from a file".to_string(),
            parameters: json!({
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Path to the file to read"},
                    "max_bytes": {"type": "integer", "description": "Maximum bytes to read", "default": null},
                    "encoding": {"type": "string", "description": "Text encoding", "default": "utf-8"}
                },
                "required": ["path"]
            }),
        },
        FunctionDeclaration {
            name: "write_file".to_string(),
            description: "Write content to a file".to_string(),
            parameters: json!({
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Path to the file to write"},
                    "content": {"type": "string", "description": "Content to write to the file"},
                    "encoding": {"type": "string", "description": "Text encoding", "default": "utf-8"}
                },
                "required": ["path", "content"]
            }),
        },
        FunctionDeclaration {
            name: "edit_file".to_string(),
            description: "Edit a file by replacing text".to_string(),
            parameters: json!({
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Path to the file to edit"},
                    "old_string": {"type": "string", "description": "Text to replace"},
                    "new_string": {"type": "string", "description": "Replacement text"},
                    "encoding": {"type": "string", "description": "Text encoding", "default": "utf-8"}
                },
                "required": ["path", "old_string", "new_string"]
            }),
        },
    ]
}
