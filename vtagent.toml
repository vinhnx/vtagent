# VTAgent Configuration - Updated Model Setup

[agent]
default_model = "gemini-2.5-flash-lite" # Specify the default model for agent mode
provider = "gemini" # Options: openai, anthropic, gemini, openrouter, lmstudio
max_conversation_turns = 150
# Reasoning effort level for models that support it (low, medium, high)
# Applies to: Claude, GPT-5, Gemini, Qwen3, DeepSeek with reasoning capability
reasoning_effort = "medium"

[security]
human_in_the_loop = true

[multi_agent]
# Enable multi-agent mode (default: false)
enabled = false
# Use single model for all agents when multi-agent is enabled (default: true)
use_single_model = true
# Main orchestrator agent model (used when multi-agent is enabled)
orchestrator_model =  "gemini-2.5-flash"
# Executor agent model (used for single-agent mode and as subagents in multi-agent mode)
executor_model = ""
# Maximum number of concurrent subagents
max_concurrent_subagents = 3
# Enable context sharing between agents
context_sharing_enabled = true
# Task execution timeout in seconds
task_timeout_seconds = 300

[lmstudio]
# LMStudio-specific configuration
base_url = "http://localhost:1234/v1"
# Model to use for single-agent mode
single_agent_model = "qwen/qwen3-4b-2507"
# Model to use for multi-agent orchestrator
orchestrator_model = "qwen/qwen3-4b-2507"
# Model to use for multi-agent subagents
subagent_model = "qwen/qwen3-4b-2507"
# Enable LMStudio for multi-agent mode (previously forced to use Gemini)
enable_multi_agent = true
# Connection timeout in seconds
connection_timeout_seconds = 30

[tools]
default_policy = "prompt"

[commands]
allow_list = ["ls", "pwd", "cat", "grep", "git status", "git diff"]

[pty]
enabled = true
default_rows = 24
default_cols = 80
max_sessions = 10
command_timeout_seconds = 300
